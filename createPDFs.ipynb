{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.pdfgen import canvas\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "\n",
    "\n",
    "url = 'https://vnexpress.net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    # Gửi yêu cầu HTTP đến trang web\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Lấy HTML của trang web\n",
    "    html = response.text\n",
    "\n",
    "    # Phân tích HTML bằng BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Tìm tất cả các thẻ h3 chứa tiêu đề trên trang\n",
    "    titles = soup.find_all('h3')\n",
    "\n",
    "    titles_list = []\n",
    "    for title in titles:\n",
    "        titles_list.append(title.text)\n",
    "    titles_list = [s.replace('\\n', '') for s in titles_list]\n",
    "    for i in range(len(titles_list)):\n",
    "        titles_list[i] = titles_list[i].strip()\n",
    "    return titles_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_by_title(title, url):\n",
    "    # Gửi yêu cầu HTTP đến trang web\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Lấy HTML của trang web\n",
    "    html = response.text\n",
    "\n",
    "    # Phân tích HTML bằng BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Tìm tất cả các thẻ a chứa tiêu đề trên trang\n",
    "    links = soup.find_all('a', {'title': title})\n",
    "\n",
    "    # Kiểm tra xem có tìm thấy liên kết không\n",
    "    if len(links) == 0:\n",
    "        print('Không tìm thấy liên kết cho tiêu đề này')\n",
    "    else:\n",
    "        # Trả về liên kết đầu tiên tìm được\n",
    "        return links[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "\n",
    "    # Lấy nội dung của trang web\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "\n",
    "    # Phân tích cú pháp HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    # Lấy phần tử p  cí class description\n",
    "    description =soup.find(['p'], class_= 'description')\n",
    "    # Lấy tất cả các phần tử p và figure có class là Normal\n",
    "    normal_elements = soup.find_all(['p', 'figure'], class_='Normal')\n",
    "\n",
    "    # In ra nội dung của các phần tử đó\n",
    "    content = []\n",
    "    if description:\n",
    "        content.append(description.text.strip())\n",
    "    for i in normal_elements:\n",
    "        content.append(i.text.strip())\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = get_title(url)[0]\n",
    "content = get_content(get_link_by_title(title, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_newspaper_to_pdf(articles):\n",
    "    filename = \"newspaper.pdf\"\n",
    "    doc = canvas.Canvas(filename, pagesize=letter)\n",
    "\n",
    "    # Set font properties\n",
    "    font_name = \"Arial\"  # Tên font bạn muốn sử dụng\n",
    "    font_size = 14\n",
    "\n",
    "    # Load and register the font\n",
    "    font_path = \"arial-unicode-ms.ttf\"  # Đường dẫn đến tệp font chữ tiếng Việt\n",
    "    pdfmetrics.registerFont(TTFont(font_name, font_path))\n",
    "\n",
    "    first_page = True  # Biến để theo dõi trang đầu tiên\n",
    "\n",
    "    for article in articles:\n",
    "        label = article[\"label\"]\n",
    "        content = article[\"content\"]\n",
    "\n",
    "        if not first_page:\n",
    "            doc.showPage()  # Chỉ chuyển trang từ trang thứ hai trở đi\n",
    "\n",
    "        # Set font for label\n",
    "        doc.setFont(font_name, font_size)\n",
    "\n",
    "        y = letter[1] - inch\n",
    "\n",
    "        # Split the label into multiple lines if needed\n",
    "        label_lines = []\n",
    "        words = label.split(' ')\n",
    "        current_line = ''\n",
    "        for word in words:\n",
    "            if doc.stringWidth(current_line + word) < letter[0] - 2 * inch:\n",
    "                current_line += word + ' '\n",
    "            else:\n",
    "                label_lines.append(current_line.strip())\n",
    "                current_line = word + ' '\n",
    "        label_lines.append(current_line.strip())\n",
    "\n",
    "        for line in label_lines:\n",
    "            doc.drawString(inch, y, line)\n",
    "            y -= font_size + 2\n",
    "\n",
    "        # Move the cursor down by half an inch to make space for the content\n",
    "        y -= 0.5 * inch\n",
    "\n",
    "        # Set font for content\n",
    "        doc.setFont(font_name, 12)\n",
    "\n",
    "        lines = []\n",
    "        for line in content:\n",
    "            words = line.split(' ')\n",
    "            current_line = ''\n",
    "            for word in words:\n",
    "                if doc.stringWidth(current_line + word) < letter[0] - 2 * inch:\n",
    "                    current_line += word + ' '\n",
    "                else:\n",
    "                    lines.append(current_line.strip())\n",
    "                    current_line = word + ' '\n",
    "            lines.append(current_line)\n",
    "        for line in lines:\n",
    "            if y <= 0.5 * inch:\n",
    "                doc.showPage()  # Chuyển sang trang mới\n",
    "                doc.setFont(font_name, 12)  # Đặt lại font\n",
    "                y = letter[1] - 2 * inch - font_size - 2\n",
    "            doc.drawString(inch, y, line)\n",
    "            y -= font_size + 2\n",
    "\n",
    "        first_page = False  # Đánh dấu đã qua trang đầu tiên\n",
    "\n",
    "    doc.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "articles =[]\n",
    "for i in range(N):\n",
    "    label = get_title(url)[i]\n",
    "    content = get_content(get_link_by_title(title, url))\n",
    "    article = {\n",
    "        \"label\": label,\n",
    "        \"content\": content\n",
    "    }\n",
    "    articles.append(article)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_newspaper_to_pdf(articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Translate_Web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
